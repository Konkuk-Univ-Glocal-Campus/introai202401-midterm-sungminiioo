{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 shape: (10000, 28, 28)\n",
      "레이블 shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        # 매직 넘버 읽기\n",
    "        magic = int.from_bytes(f.read(4), 'big')\n",
    "        if magic != 2051:\n",
    "            raise ValueError(\"Invalid magic number in MNIST image file: {}\".format(magic))\n",
    "        \n",
    "        # 이미지 수, 행, 열 읽기\n",
    "        num_images = int.from_bytes(f.read(4), 'big')\n",
    "        num_rows = int.from_bytes(f.read(4), 'big')\n",
    "        num_cols = int.from_bytes(f.read(4), 'big')\n",
    "        \n",
    "        # 이미지 데이터 읽기\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape((num_images, num_rows, num_cols))\n",
    "        \n",
    "        return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        # 매직 넘버 읽기\n",
    "        magic = int.from_bytes(f.read(4), 'big')\n",
    "        if magic != 2049:\n",
    "            raise ValueError(\"Invalid magic number in MNIST label file: {}\".format(magic))\n",
    "        \n",
    "        # 레이블 수 읽기\n",
    "        num_labels = int.from_bytes(f.read(4), 'big')\n",
    "        \n",
    "        # 레이블 데이터 읽기\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        \n",
    "        return labels\n",
    "\n",
    "# 파일 경로 설정\n",
    "images_path = 't10k-images-idx3-ubyte.gz'\n",
    "labels_path = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# MNIST 이미지와 레이블 로드\n",
    "images = load_mnist_images(images_path)\n",
    "labels = load_mnist_labels(labels_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"이미지 shape:\", images.shape)\n",
    "print(\"레이블 shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 이미지 shape: (7000, 28, 28)\n",
      "테스트 이미지 shape: (3000, 28, 28)\n",
      "학습 레이블 shape: (7000,)\n",
      "테스트 레이블 shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분리\n",
    "\n",
    "num_test_samples = 3000\n",
    "\n",
    "train_images = images[:-num_test_samples]\n",
    "test_images = images[-num_test_samples:]\n",
    "train_labels = labels[:-num_test_samples]\n",
    "test_labels = labels[-num_test_samples:]\n",
    "\n",
    "# 데이터 형태 확인\n",
    "print(\"학습 이미지 shape:\", train_images.shape)\n",
    "print(\"테스트 이미지 shape:\", test_images.shape)\n",
    "print(\"학습 레이블 shape:\", train_labels.shape)\n",
    "print(\"테스트 레이블 shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 스케일링 (0에서 255 사이의 값을 0에서 1 사이로 스케일링)\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# 레이블 형 변환 (정수형에서 부동 소수점으로 변환)\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_labels = test_labels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 레이블의 원핫 인코딩 결과: (7000, 10)\n",
      "테스트 레이블의 원핫 인코딩 결과: (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 학습 레이블과 테스트 레이블을 원핫 인코딩합니다.\n",
    "num_classes = 10  # MNIST 데이터셋은 숫자 0부터 9까지 총 10개의 클래스가 있습니다.\n",
    "\n",
    "train_labels_onehot = np.eye(num_classes)[train_labels.astype('int')]\n",
    "test_labels_onehot = np.eye(num_classes)[test_labels.astype('int')]\n",
    "\n",
    "# 결과 확인\n",
    "print(\"학습 레이블의 원핫 인코딩 결과:\", train_labels_onehot.shape)\n",
    "print(\"테스트 레이블의 원핫 인코딩 결과:\", test_labels_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 이미지 shape: (5600, 28, 28)\n",
      "학습 레이블 shape: (5600, 10)\n",
      "검증 이미지 shape: (1400, 28, 28)\n",
      "검증 레이블 shape: (1400, 10)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터를 더 작은 학습 데이터와 검증 데이터로 분리합니다.\n",
    "validation_ratio = 0.2  # 검증 데이터의 비율\n",
    "\n",
    "num_train_samples = len(train_images)\n",
    "num_validation_samples = int(num_train_samples * validation_ratio)\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분리\n",
    "validation_images = train_images[-num_validation_samples:]\n",
    "validation_labels = train_labels_onehot[-num_validation_samples:]\n",
    "train_images = train_images[:-num_validation_samples]\n",
    "train_labels_onehot = train_labels_onehot[:-num_validation_samples]\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"학습 이미지 shape:\", train_images.shape)\n",
    "print(\"학습 레이블 shape:\", train_labels_onehot.shape)\n",
    "print(\"검증 이미지 shape:\", validation_images.shape)\n",
    "print(\"검증 레이블 shape:\", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 이미지 shape: (8000, 28, 28)\n",
      "학습 레이블 shape: (8000,)\n",
      "검증 이미지 shape: (1000, 28, 28)\n",
      "검증 레이블 shape: (1000,)\n",
      "테스트 이미지 shape: (1000, 28, 28)\n",
      "테스트 레이블 shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 학습, 검증, 테스트 데이터셋으로 분리합니다.\n",
    "def split_dataset(images, labels, validation_ratio=0.1, test_ratio=0.1): # 검증 데이터의 비율\n",
    "    num_samples = len(images)\n",
    "    num_validation_samples = int(num_samples * validation_ratio)\n",
    "    num_test_samples = int(num_samples * test_ratio)\n",
    "\n",
    "    # 데이터를 랜덤하게 섞습니다.\n",
    "    np.random.seed(42)\n",
    "    shuffle_indices = np.random.permutation(num_samples)\n",
    "    images_shuffled = images[shuffle_indices]\n",
    "    labels_shuffled = labels[shuffle_indices]\n",
    "\n",
    "    # 학습, 검증, 테스트 데이터셋으로 분리합니다.\n",
    "    validation_images = images_shuffled[:num_validation_samples]\n",
    "    validation_labels = labels_shuffled[:num_validation_samples]\n",
    "    test_images = images_shuffled[num_validation_samples:num_validation_samples + num_test_samples]\n",
    "    test_labels = labels_shuffled[num_validation_samples:num_validation_samples + num_test_samples]\n",
    "    train_images = images_shuffled[num_validation_samples + num_test_samples:]\n",
    "    train_labels = labels_shuffled[num_validation_samples + num_test_samples:]\n",
    "\n",
    "    return train_images, train_labels, validation_images, validation_labels, test_images, test_labels\n",
    "\n",
    "# 학습, 검증, 테스트 데이터셋 생성\n",
    "train_images, train_labels_onehot, validation_images, validation_labels_onehot, test_images, test_labels_onehot = split_dataset(images, labels, validation_ratio=0.1, test_ratio=0.1)\n",
    "\n",
    "# 데이터셋 형태 확인\n",
    "print(\"학습 이미지 shape:\", train_images.shape)\n",
    "print(\"학습 레이블 shape:\", train_labels_onehot.shape)\n",
    "print(\"검증 이미지 shape:\", validation_images.shape)\n",
    "print(\"검증 레이블 shape:\", validation_labels_onehot.shape)\n",
    "print(\"테스트 이미지 shape:\", test_images.shape)\n",
    "print(\"테스트 레이블 shape:\", test_labels_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in /home/codespace/.local/lib/python3.10/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch==2.2.2->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchvision) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch==2.2.2->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 생성\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 데이터셋 로드\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 선택\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 알고리즘 선택\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.007, accuracy: 69.56 %\n",
      "[1,   200] loss: 0.246, accuracy: 92.70 %\n",
      "[1,   300] loss: 0.168, accuracy: 95.09 %\n",
      "[1,   400] loss: 0.121, accuracy: 96.22 %\n",
      "[1,   500] loss: 0.106, accuracy: 96.84 %\n",
      "[1,   600] loss: 0.095, accuracy: 96.89 %\n",
      "[1,   700] loss: 0.085, accuracy: 97.45 %\n",
      "[1,   800] loss: 0.086, accuracy: 97.42 %\n",
      "[1,   900] loss: 0.075, accuracy: 97.84 %\n",
      "[2,   100] loss: 0.067, accuracy: 97.89 %\n",
      "[2,   200] loss: 0.054, accuracy: 98.19 %\n",
      "[2,   300] loss: 0.050, accuracy: 98.33 %\n",
      "[2,   400] loss: 0.055, accuracy: 98.28 %\n",
      "[2,   500] loss: 0.050, accuracy: 98.36 %\n",
      "[2,   600] loss: 0.047, accuracy: 98.47 %\n",
      "[2,   700] loss: 0.053, accuracy: 98.42 %\n",
      "[2,   800] loss: 0.056, accuracy: 98.23 %\n",
      "[2,   900] loss: 0.055, accuracy: 98.45 %\n",
      "[3,   100] loss: 0.039, accuracy: 98.75 %\n",
      "[3,   200] loss: 0.034, accuracy: 98.92 %\n",
      "[3,   300] loss: 0.040, accuracy: 98.67 %\n",
      "[3,   400] loss: 0.042, accuracy: 98.62 %\n",
      "[3,   500] loss: 0.038, accuracy: 98.62 %\n",
      "[3,   600] loss: 0.046, accuracy: 98.66 %\n",
      "[3,   700] loss: 0.040, accuracy: 98.73 %\n",
      "[3,   800] loss: 0.038, accuracy: 98.80 %\n",
      "[3,   900] loss: 0.039, accuracy: 98.62 %\n",
      "[4,   100] loss: 0.019, accuracy: 99.36 %\n",
      "[4,   200] loss: 0.028, accuracy: 99.08 %\n",
      "[4,   300] loss: 0.031, accuracy: 98.98 %\n",
      "[4,   400] loss: 0.033, accuracy: 98.97 %\n",
      "[4,   500] loss: 0.038, accuracy: 98.77 %\n",
      "[4,   600] loss: 0.027, accuracy: 99.12 %\n",
      "[4,   700] loss: 0.028, accuracy: 99.22 %\n",
      "[4,   800] loss: 0.034, accuracy: 99.02 %\n",
      "[4,   900] loss: 0.029, accuracy: 99.09 %\n",
      "[5,   100] loss: 0.021, accuracy: 99.33 %\n",
      "[5,   200] loss: 0.021, accuracy: 99.39 %\n",
      "[5,   300] loss: 0.020, accuracy: 99.36 %\n",
      "[5,   400] loss: 0.020, accuracy: 99.38 %\n",
      "[5,   500] loss: 0.024, accuracy: 99.23 %\n",
      "[5,   600] loss: 0.020, accuracy: 99.33 %\n",
      "[5,   700] loss: 0.031, accuracy: 98.92 %\n",
      "[5,   800] loss: 0.026, accuracy: 99.30 %\n",
      "[5,   900] loss: 0.017, accuracy: 99.38 %\n"
     ]
    }
   ],
   "source": [
    "def train(model, trainloader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f, accuracy: %.2f %%' % \n",
    "                      (epoch + 1, i + 1, running_loss / 100, 100 * correct / total))\n",
    "                running_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "# 모델 훈련\n",
    "train(model, trainloader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 정확도: 98.69 %\n"
     ]
    }
   ],
   "source": [
    "def test(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('테스트 세트 정확도: %.2f %%' % (100 * correct / total))\n",
    "\n",
    "# 모델 테스트\n",
    "test(model, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
